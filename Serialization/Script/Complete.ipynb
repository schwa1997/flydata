{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from urllib.parse import quote\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "from rdflib.namespace import XSD, RDFS\n",
    "from meteostat import Point, Hourly\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths\n",
    "BASE_PATH = Path(r\"D:\\\\OneDrive - Universit√† degli Studi di Padova\\\\Lezioni\\\\Magistrale\\\\Terzo semestre\\\\Graph DB\\\\Homework\\\\flydata\")\n",
    "AIRPORTS_PATH = BASE_PATH / \"DataCollection\" / \"CSVData\" / \"airports.csv\"\n",
    "CITIES_PATH = BASE_PATH / \"DataCollection\" / \"CSVData\" / \"cities.csv\"\n",
    "FLIGHTS_PATH = BASE_PATH / \"DataCollection\" / \"CSVData\" / \"flights.csv\"\n",
    "OUTPUT_PATH_AIRPORT = BASE_PATH / \"Serialization\" /\"ttl\"/ \"airport.ttl\"\n",
    "OUTPUT_PATH_CITY = BASE_PATH / \"Serialization\" /\"ttl\"/ \"city.ttl\"\n",
    "OUTPUT_PATH_WEATHER = BASE_PATH / \"Serialization\" /\"ttl\"/ \"weather.ttl\"\n",
    "OUTPUT_PATH_FLIGHTS = BASE_PATH / \"Serialization\" /\"ttl\"/ \"flights.ttl\"\n",
    "\n",
    "\n",
    "# Define namespaces\n",
    "FDO = Namespace(\"http://www.semanticweb.org/nele/ontologies/2024/10/flydata/\")\n",
    "\n",
    "# Define the time interval for the weather data\n",
    "start = pd.to_datetime('2024-8-1')\n",
    "end = pd.to_datetime('2024-8-31')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N4ddb4f560ec1498aa0b277ffee1e06f5 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_city = Graph()\n",
    "\n",
    "g_city.bind(\"fdo\", FDO)\n",
    "g_city.bind(\"xsd\", XSD)\n",
    "\n",
    "cities = {}\n",
    "try:\n",
    "    # Load the CSV file in memory using pandas\n",
    "    cities_df = pd.read_csv(CITIES_PATH)\n",
    "    for _, row in cities_df.iterrows():\n",
    "        # Convert city_ascii to string and skip if it's NaN\n",
    "        if pd.isna(row['city_ascii']):\n",
    "            continue\n",
    "            \n",
    "        city_ascii = str(row['city_ascii'])\n",
    "        cities[city_ascii] = {\n",
    "            'name': row['city'],\n",
    "            'population': str(row['population']) if pd.notna(row['population']) else \"0\"\n",
    "        }\n",
    "                    \n",
    "except Exception as e:\n",
    "    print(f\"Error reading file: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Add cities to the city graph\n",
    "for city_ascii, data in cities.items():\n",
    "    # Remove special characters and spaces, then URL encode\n",
    "    city_id = quote(city_ascii.encode('ascii', 'ignore').decode().replace(\" \", \"_\").replace(\"'\", \"\").replace(\",\", \"\"))\n",
    "    city_uri = URIRef(str(FDO) + city_id)\n",
    "    \n",
    "    # Add city triples\n",
    "    g_city.add((city_uri, RDF.type, FDO.City))\n",
    "    g_city.add((city_uri, FDO.name, Literal(data['name'], datatype=XSD.string)))\n",
    "    g_city.add((city_uri, FDO.population, Literal(data['population'], datatype=XSD.string)))\n",
    "\n",
    "g_city.serialize(destination=str(OUTPUT_PATH_CITY), format='turtle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N8ef450fb457c42f09101060ff7e79cc2 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_airport = Graph()\n",
    "\n",
    "g_airport.bind(\"fdo\", FDO)\n",
    "g_airport.bind(\"xsd\", XSD)\n",
    "\n",
    "# Define the isLocatedInCity property in the airport graph\n",
    "g_airport.add((FDO.isLocatedInCity, RDF.type, RDF.Property))\n",
    "g_airport.add((FDO.isLocatedInCity, RDFS.domain, FDO.Airport))\n",
    "g_airport.add((FDO.isLocatedInCity, RDFS.range, FDO.City))\n",
    "\n",
    "airports = []\n",
    "try:\n",
    "    with open(AIRPORTS_PATH, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if row['IATA']:  # Only include airports with IATA code\n",
    "                airports.append({\n",
    "                    'name': row['Name'].strip('\"'),\n",
    "                    'city': row['City'].strip('\"'),\n",
    "                    'iata': row['IATA'].strip('\"'),\n",
    "                    'lat': row['LAT'].strip('\"'),\n",
    "                    'long': row['LONG'].strip('\"')\n",
    "                })\n",
    "except Exception as e:\n",
    "    print(f\"Error reading airports file: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Add airports and their relationships to the airport graph\n",
    "for airport in airports:\n",
    "    # Use IATA code directly in the URI\n",
    "    airport_uri = URIRef(str(FDO) + airport['iata'])\n",
    "    \n",
    "    # Add airport triples\n",
    "    g_airport.add((airport_uri, RDF.type, FDO.Airport))\n",
    "    g_airport.add((airport_uri, FDO.name, Literal(airport['name'], datatype=XSD.string)))\n",
    "    \n",
    "    # Only add isLocatedInCity if the city exists in our cities dataset\n",
    "    if airport['city'] in cities:\n",
    "        city_id = quote(airport['city'].encode('ascii', 'ignore').decode().replace(\" \", \"_\").replace(\"'\", \"\").replace(\",\", \"\"))\n",
    "        city_uri = URIRef(str(FDO) + city_id)\n",
    "        g_airport.add((airport_uri, FDO.isLocatedInCity, city_uri))\n",
    "\n",
    "# Serialize both graphs to separate TTL files\n",
    "g_airport.serialize(destination=str(OUTPUT_PATH_AIRPORT), format='turtle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 % complete\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N9618c1849cd647fa9d4e67ae15793236 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#suppression of the meteostat warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "g_weather = Graph()\n",
    "\n",
    "g_weather.bind(\"fdo\", FDO)\n",
    "g_weather.bind(\"xsd\", XSD)\n",
    "\n",
    "# for each airport, get the weather data\n",
    "index = 0\n",
    "for airport in airports:\n",
    "    # Try to get the weather data for each airport\n",
    "    try:   \n",
    "        # Get the weather data\n",
    "        point = Point(float(airport['lat']), float(airport['long']), 0)\n",
    "        data = Hourly(point, start, end)\n",
    "        data = data.fetch()\n",
    "        \n",
    "        # Create the node to add to the Graph\n",
    "        for idx, row in data.iterrows():\n",
    "            # the node has the namespace + the airport iata + timestamp as URI\n",
    "            airport_uri = URIRef(str(FDO) + airport['iata'] + str(int(row.name.timestamp()/1000)))\n",
    "            \n",
    "            # Add airport triples\n",
    "            g_weather.add((airport_uri, RDF.type, FDO.Weather))\n",
    "            g_weather.add((airport_uri, FDO['weatherDate'], Literal(int(row.name.timestamp()), datatype=XSD.dateTime)))\n",
    "            coco_standardized = 0 if pd.isna(row.coco) else int(row.coco)\n",
    "            g_weather.add((airport_uri, FDO['weatherType'], Literal(coco_standardized, datatype=XSD.nonNegativeInteger)))\n",
    "            g_weather.add((airport_uri, FDO['hasAirport'], URIRef(FDO[airport['iata']])))\n",
    "    except Exception as e:\n",
    "        print(f\"Error weather ({airport['iata']}): {str(e)}\")\n",
    "\n",
    "    print(f\"{int(index/len(airports)*100)} % complete\\r\", end=\"\")\n",
    "    index+=1\n",
    "\n",
    "g_weather.serialize(destination=str(OUTPUT_PATH_WEATHER), format='turtle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
